{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3415848,"sourceType":"datasetVersion","datasetId":2058865},{"sourceId":7682087,"sourceType":"datasetVersion","datasetId":4482090},{"sourceId":7682103,"sourceType":"datasetVersion","datasetId":4482105},{"sourceId":7819993,"sourceType":"datasetVersion","datasetId":4581642},{"sourceId":7911313,"sourceType":"datasetVersion","datasetId":4647722}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nfrom PIL import Image\nimport cv2\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.applications.vgg16 import preprocess_input\nfrom tensorflow.keras.models import load_model\nimport matplotlib.pyplot as plt\nimport os\nimport shap","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-22T14:40:48.601325Z","iopub.execute_input":"2024-03-22T14:40:48.601786Z","iopub.status.idle":"2024-03-22T14:40:55.237574Z","shell.execute_reply.started":"2024-03-22T14:40:48.601755Z","shell.execute_reply":"2024-03-22T14:40:55.236236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = {\n    \"Brain Cancer\": {\n        0: \"Glioma\", 1: \"Meningioma\", 2: \"Pituitary Tumor\"\n    },\n    \"Breast Cancer\": {\n        0: \"Benign\", 1: \"Malignant\"\n    },\n    \"Cervical Cancer\": {\n        0: \"Dyskeratotic\", 1: \"Koilocytotic\", 2: \"Metaplastic\", 3: \"Parabasal\", 4: \"Superficial-Intermediat\"\n    },\n    \"Kidney Cancer\": {\n        0: \"Normal\", 1: \"Tumor\"\n    },\n    \"Lung and Colon Cancer\": {\n        0: \"Colon Adenocarcinoma\", 1: \"Colon Benign Tissue\", 2: \"Lung Adenocarcinoma\", 3: \"Lung Benign Tissue\", 4: \"Lung Squamous Cell Carcinoma\"\n    },\n    \"Lymphoma\": {\n        0: \"Chronic Lymphocytic Leukemia\", 1: \"Follicular Lymphoma\", 2: \"Mantle Cell Lymphoma\"\n    },\n    \"Oral Cancer\": {\n        0: \"Normal\", 1: \"Oral Squamous Cell Carcinoma\"\n    }\n}","metadata":{"execution":{"iopub.status.busy":"2024-03-22T14:40:55.239407Z","iopub.execute_input":"2024-03-22T14:40:55.240363Z","iopub.status.idle":"2024-03-22T14:40:55.248989Z","shell.execute_reply.started":"2024-03-22T14:40:55.240327Z","shell.execute_reply":"2024-03-22T14:40:55.247259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_top_predicted_indices(predictions, top_n):\n    return np.argsort(-predictions).squeeze()[:top_n]\n\ndef make_gradcam_heatmap(\n    img_array, model, \n    last_conv_layer_name, \n    classifier_layer_names,\n    top_n,\n    class_indices\n):\n    #1. Create a model that maps the input image to the activations of the last convolution layer - Get last conv layer's output dimensions\n    last_conv_layer = model.get_layer(last_conv_layer_name)\n    last_conv_layer_model = tf.keras.Model(model.inputs, last_conv_layer.output)\n    \n    #2. Create another model, that maps from last convolution layer to the final class predictions - This is the classifier model that calculated the gradient\n    classifier_input = tf.keras.Input(shape=last_conv_layer.output.shape[1:])\n    x = classifier_input\n    for layer_name in classifier_layer_names:\n        x = model.get_layer(layer_name)(x)\n    classifier_model = tf.keras.Model(classifier_input, x)\n    \n    #3. If top N predictions are to be interospected, Get their Imagenet indices else assign the indices given\n    if(top_n > 0):\n        last_conv_layer_output = last_conv_layer_model(img_array)\n        preds = classifier_model(last_conv_layer_output)\n        class_indices = get_top_predicted_indices(preds, top_n)\n    else:\n        top_n = len(class_indices)\n    \n    #4. Create an array to store the heatmaps\n    heatmaps = []\n    #5. Iteratively calculate heatmaps for all classes of interest using GradientTape\n    for index in np.arange(top_n):\n    \n        #6. Watch the last convolution output during the prediction process to calculate the gradients\n        #7. Compute the activations of last conv layer and make the tape to watch\n        with tf.GradientTape() as tape:\n            # Compute activations of the last conv layer and make the tape watch it\n            last_conv_layer_output = last_conv_layer_model(img_array)\n            tape.watch(last_conv_layer_output)\n\n            #8. Get the class predictions and the class channel using the class index\n            preds = classifier_model(last_conv_layer_output)\n            class_channel = tf.gather(preds[0], class_indices[index], axis=-1) \n            \n        #9. Using tape, Get the gradient for the predicted class wrt the output feature map of last conv layer    \n        grads = tape.gradient(\n            class_channel,\n            last_conv_layer_output\n        )\n        \n        #10. Calculate the mean intensity of the gradient over its feature map channel\n        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))    \n        last_conv_layer_output = last_conv_layer_output.numpy()[0]\n        pooled_grads = pooled_grads.numpy()\n        \n        #11. Multiply each channel in feature map array by weight importance of the channel\n        for i in range(pooled_grads.shape[-1]):\n            last_conv_layer_output[:, :, i] *= pooled_grads[i]\n\n        #12. The channel-wise mean of the resulting feature map is our heatmap of class activation\n        heatmap = np.mean(last_conv_layer_output, axis=-1)\n\n        #13. Normalize the heatmap between [0, 1] for ease of visualization\n        max_heatmap = np.max(heatmap)\n        if max_heatmap != 0:\n            heatmap = np.maximum(heatmap, 0) / max_heatmap\n        else:\n            heatmap = np.maximum(heatmap, 0)\n#                 heatmap = np.maximum(heatmap, 0) / np.max(heatmap)\n\n        heatmaps.append({\n            \"class_id\": class_indices[index],\n            \"heatmap\": heatmap\n        })\n\n    return heatmaps","metadata":{"execution":{"iopub.status.busy":"2024-03-22T14:40:55.250663Z","iopub.execute_input":"2024-03-22T14:40:55.251119Z","iopub.status.idle":"2024-03-22T14:40:55.270392Z","shell.execute_reply.started":"2024-03-22T14:40:55.251087Z","shell.execute_reply":"2024-03-22T14:40:55.269153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_and_preprocess_image(img_path):\n    img = image.load_img(img_path, target_size=(224, 224))\n    img = image.img_to_array(img)\n    img = np.expand_dims(img, axis=0)\n    img = preprocess_input(img)\n    return img","metadata":{"execution":{"iopub.status.busy":"2024-03-22T14:40:55.273145Z","iopub.execute_input":"2024-03-22T14:40:55.274296Z","iopub.status.idle":"2024-03-22T14:40:55.288403Z","shell.execute_reply.started":"2024-03-22T14:40:55.274250Z","shell.execute_reply":"2024-03-22T14:40:55.287457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def superimpose_heatmap(image_path, heatmap):\n    img = tf.keras.preprocessing.image.load_img(image_path)\n    img = tf.keras.preprocessing.image.img_to_array(img)\n    \n    # We rescale heatmap to a range 0-255\n    heatmap = np.uint8(255 * heatmap)\n    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n    heatmap = tf.keras.preprocessing.image.array_to_img(heatmap)\n    heatmap = heatmap.resize((img.shape[1], img.shape[0]))\n    \n    heatmap = tf.keras.preprocessing.image.img_to_array(heatmap)\n    superimposed_img = cv2.addWeighted(heatmap, 0.4, img, 0.6, 0)\n    superimposed_img = np.uint8(superimposed_img)\n    \n    return superimposed_img","metadata":{"execution":{"iopub.status.busy":"2024-03-22T14:40:55.289769Z","iopub.execute_input":"2024-03-22T14:40:55.290955Z","iopub.status.idle":"2024-03-22T14:40:55.300672Z","shell.execute_reply.started":"2024-03-22T14:40:55.290921Z","shell.execute_reply":"2024-03-22T14:40:55.299245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef display_superimposed_heatmaps(heatmaps, image_path, image_id, pred_class):\n    n = len(heatmaps)\n    n_rows = (n // 3) + 1 if n % 3 > 0 else n // 3\n    plt.rcParams['axes.grid'] = False\n    plt.rcParams['xtick.labelsize'] = False\n    plt.rcParams['ytick.labelsize'] = False\n    plt.rcParams['xtick.top'] = False\n    plt.rcParams['xtick.bottom'] = False\n    plt.rcParams['ytick.left'] = False\n    plt.rcParams['ytick.right'] = False\n    plt.rcParams['figure.figsize'] = [30, 15]\n    for index in np.arange(n):\n        heatmap = heatmaps[index][\"heatmap\"]\n        class_id = heatmaps[index][\"class_id\"]\n        class_name = pred_class\n        superimposed_image = superimpose_heatmap(image_path, heatmap)\n        plt.subplot(n_rows, 3, index+1)\n        plt.title(f\"{class_id}, {class_name}\", fontsize= 20)\n        plt.imshow(superimposed_image)\n        \n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-03-22T14:40:55.305731Z","iopub.execute_input":"2024-03-22T14:40:55.306187Z","iopub.status.idle":"2024-03-22T14:40:55.319759Z","shell.execute_reply.started":"2024-03-22T14:40:55.306146Z","shell.execute_reply":"2024-03-22T14:40:55.318596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_class(img, model):\n    img = Image.open(img)\n\n    img = img.resize((224, 224))  \n    img = image.img_to_array(img)\n    img = np.expand_dims(img, axis=0)\n\n    predictions = model.predict(img)\n    predicted_class_idx = np.argmax(predictions, axis=1)[0]  # Get the index of the max predicted class\n    return predictions, img, predicted_class_idx\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-22T14:40:55.321367Z","iopub.execute_input":"2024-03-22T14:40:55.322027Z","iopub.status.idle":"2024-03-22T14:40:55.333064Z","shell.execute_reply.started":"2024-03-22T14:40:55.321996Z","shell.execute_reply":"2024-03-22T14:40:55.331864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **GRADCAM - 2**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport cv2\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.applications.vgg16 import preprocess_input\nfrom tensorflow.keras.models import load_model\nimport matplotlib.pyplot as plt\n\ndef grad_cam_plus_plus(model, img_array, layer_name, pred_index=None):\n    \n    grad_model = tf.keras.models.Model([model.inputs], [model.get_layer(layer_name).output, model.output])\n\n    # Then, we compute the gradient of the top predicted class for our input image\n    # with respect to the activations of the last conv layer\n    with tf.GradientTape() as tape:\n        last_conv_layer_output, preds = grad_model(img_array)\n        if pred_index is None:\n            pred_index = tf.argmax(preds[0])\n        class_channel = preds[:, pred_index]\n\n    # This is the gradient of the output neuron (top predicted or chosen) with regard to\n    # the output feature map of the last conv layer\n    grads = tape.gradient(class_channel, last_conv_layer_output)\n\n    # This is a vector where each entry is the mean intensity of the gradient\n    # over a specific feature map channel\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n\n    # We multiply each channel in the feature map array\n    # by \"how important this channel is\" with regard to the top predicted class\n    # then sum all the channels to obtain the heatmap class activation\n    last_conv_layer_output = last_conv_layer_output[0]\n    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n\n    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n    return heatmap.numpy()\n\ndef load_and_preprocess_image(img_path):\n    img = image.load_img(img_path, target_size=(224, 224))\n    img = image.img_to_array(img)\n    img = np.expand_dims(img, axis=0)\n    img = preprocess_input(img)\n    return img\n\n\ndef apply_heatmap(heatmap, original_img_path, intensity=0.5, colormap=cv2.COLORMAP_JET):\n    original_img = cv2.imread(original_img_path)\n    heatmap_resized = cv2.resize(heatmap, (original_img.shape[1], original_img.shape[0]))\n    heatmap_resized = np.maximum(heatmap_resized, 0)\n    heatmap_resized = heatmap_resized / np.max(heatmap_resized)\n    heatmap_resized = np.uint8(255 * heatmap_resized)\n    heatmap_resized = cv2.applyColorMap(heatmap_resized, colormap)\n    superimposed_img = heatmap_resized * intensity + original_img\n    superimposed_img = np.clip(superimposed_img, 0, 255).astype(np.uint8)\n    return superimposed_img\n\n# Load your model\nmodel = load_model('/kaggle/input/efficient-net/Efficient Net/Breast Cancer  - EfficientNetB0.keras', compile=False)\n\n# Prepare the image\nimg_path = '/kaggle/input/test-data/test/Breast Cancer/breast_malignant_4202.jpg'\nimg_array = load_and_preprocess_image(img_path)\n\n# Generate Grad-CAM++ heatmap\nheatmap = grad_cam_plus_plus(model, img_array, 'top_activation')  # Specify the last conv layer name\n\n# Overlay and display the heatmap\n#overlay_heatmap(heatmap, img_path)\n\nsuperimposed_img = apply_heatmap(heatmap, img_path)\n\nsuperimposed_img_rgb = cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize=(6, 6))\nplt.imshow(superimposed_img)\nplt.axis('off')\nplt.title('Image with Grad-CAM++ Heatmap')\nplt.show()\n\n# If you want to display the image within a Jupyter notebook you can use the following:\n# from IPython.display import Image, display\n# display(Image('/mnt/data/cervix_cancer_gradcam++.jpg'))","metadata":{"execution":{"iopub.status.busy":"2024-03-22T16:15:45.087206Z","iopub.execute_input":"2024-03-22T16:15:45.087756Z","iopub.status.idle":"2024-03-22T16:15:51.111365Z","shell.execute_reply.started":"2024-03-22T16:15:45.087711Z","shell.execute_reply":"2024-03-22T16:15:51.110268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **SHAP**","metadata":{}},{"cell_type":"code","source":"def load_background_batch():\n\n    test_dir = '/kaggle/input/test-data/test'\n    batch_data = []\n\n    for dirc in os.listdir(test_dir):\n        dir_path = os.path.join(test_dir, dirc)\n        image_files = os.listdir(dir_path)\n\n        background_data = []\n\n        for img_file in image_files:\n            img_path = os.path.join(dir_path, img_file)\n            img = image.load_img(img_path, target_size=(224, 224))\n            img_array = image.img_to_array(img)\n            img_array = np.expand_dims(img_array, axis=0)  \n            background_data.append(img_array)\n\n        background_batch = np.vstack(background_data)\n\n        batch_data.append(background_batch)\n\n\n    return batch_data","metadata":{"execution":{"iopub.status.busy":"2024-03-22T14:41:02.005304Z","iopub.execute_input":"2024-03-22T14:41:02.006411Z","iopub.status.idle":"2024-03-22T14:41:02.016814Z","shell.execute_reply.started":"2024-03-22T14:41:02.006348Z","shell.execute_reply":"2024-03-22T14:41:02.015077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def shap_explanation(model, img_array, background):\n    explainer = shap.DeepExplainer(model, background)\n    shap_values = explainer.shap_values(img_array)\n    return shap_values","metadata":{"execution":{"iopub.status.busy":"2024-03-22T14:41:02.020775Z","iopub.execute_input":"2024-03-22T14:41:02.021891Z","iopub.status.idle":"2024-03-22T14:41:02.043102Z","shell.execute_reply.started":"2024-03-22T14:41:02.021842Z","shell.execute_reply":"2024-03-22T14:41:02.041761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef show_shap(shap_values, img_array, predicted_class_idx, class_names):\n    \n    if len(img_array.shape) == 3:\n        img_array = np.expand_dims(img_array, axis=0)\n\n    # Get the SHAP values for the predicted class\n    shap_values_for_predicted_class = shap_values[predicted_class_idx]\n\n    # Plotting\n    plt.figure()\n    shap.image_plot(shap_values_for_predicted_class, img_array)\n    plt.show()\n    \n    # Print the predicted class\n    predicted_class_name = class_names[predicted_class_idx]\n    st.warning(f\"Model predicted: {predicted_class_name}\")\n\n    st.write('Inference for the Prediction: Plot of SHAP values')\n    st.pyplot(plt.gcf())","metadata":{"execution":{"iopub.status.busy":"2024-03-22T14:41:02.044557Z","iopub.execute_input":"2024-03-22T14:41:02.044987Z","iopub.status.idle":"2024-03-22T14:41:02.055141Z","shell.execute_reply.started":"2024-03-22T14:41:02.044948Z","shell.execute_reply":"2024-03-22T14:41:02.053475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **RESULT - GRADCAM AND SHAP**","metadata":{}},{"cell_type":"code","source":"\n# Load your model (ensure the path is correct and accessible)\nmodel = load_model('/kaggle/input/efficient-net/Efficient Net/Lymphoma  - EfficientNetB0.keras', compile=False)\n\n# Prepare the image\nimg_path = '/kaggle/input/test-data/test/Lymphoma/lymph_mcl_0543.jpg'\nimg_array = load_and_preprocess_image(img_path)\n\npredictions, img, predicted_class_idx = predict_class(img_path, model)\n\npredicted_class_name = classes[\"Lymphoma\"][predicted_class_idx]\nprint(f\"Model predicted: {predicted_class_name}\")\nprint(np.argmax(predictions))\n\n# Generate Grad-CAM++ heatmap\n# heatmap = grad_cam_plus_plus(model, img_array, 'block5_conv3')  # Ensure 'block5_conv3' is the correct layer\nclassifier_layer_names = ['top_activation']\n#make_gradcam_heatmap(img_array, model, 'top_activation', ['top_activation'], None, None)\nheatmaps = make_gradcam_heatmap(img_array, model, 'top_activation', classifier_layer_names, 1, None)\ndisplay_superimposed_heatmaps(heatmaps, img_path, 1,predicted_class_name)\n\n\n#SHAP \n# background_batch_data = load_background_batch()\n# cancer_classes = list(classes.keys())\n# background_batch = background_batch_data[cancer_classes.index(\"Cervical Cancer\")]\n# shap_values = shap_explanation(model, img, background_batch)\n# background_batch_data = load_background_batch()\n# show_shap(shap_values, img, predicted_class_idx, classes[\"Cervical Cancer\"])\n    \n# SHAP explanation\nexplainer = shap.DeepExplainer(model, img_array)\nshap_values = explainer.shap_values(img_array)\n\n# Plot the SHAP values\nshap.image_plot(shap_values[0], -img_array)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-22T14:41:02.056879Z","iopub.execute_input":"2024-03-22T14:41:02.057499Z","iopub.status.idle":"2024-03-22T14:41:15.333121Z","shell.execute_reply.started":"2024-03-22T14:41:02.057448Z","shell.execute_reply":"2024-03-22T14:41:15.331465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom PIL import Image\nimport cv2\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras import backend as K\nfrom keras.utils import img_to_array\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.applications.vgg16 import preprocess_input\nfrom tensorflow.keras.models import load_model\nimport matplotlib.pyplot as plt\nimport os\n\ndef get_img_array(img_path, size=(224, 224)):\n    img = keras.utils.load_img(img_path, target_size=size)\n    array = keras.utils.img_to_array(img)\n    array = np.uint8(array)\n    #array = np.expand_dims(array, axis=0)\n    return array\n\ndef make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n\n    grad_model = keras.models.Model(\n        model.inputs, [model.get_layer(last_conv_layer_name).output, model.output]\n    )\n\n    with tf.GradientTape() as tape:\n        last_conv_layer_output, preds = grad_model(img_array)\n        if pred_index is None:\n            pred_index = tf.argmax(preds[0])\n        class_channel = preds[:, pred_index]\n\n    grads = tape.gradient(class_channel, last_conv_layer_output)\n\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1))\n\n    last_conv_layer_output = last_conv_layer_output[0]\n    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n    # print(heatmap.shape)\n    heatmap = tf.squeeze(heatmap)\n\n    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n    # print(heatmap.shape)\n    return pred_index.numpy(), heatmap.numpy()\n\n\ndef superimpose(img, cam):\n\n    heatmap = cv2.resize(cam, (img.shape[1], img.shape[0]))\n    heatmap = np.uint8(255 * heatmap)\n    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n\n    superimposed_img = heatmap * 0.5 + img * 0.5\n    superimposed_img = np.minimum(superimposed_img, 255.0).astype(\n        np.uint8\n    )\n    superimposed_img = cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB)\n\n    return img, heatmap, superimposed_img\ndef plot_org_img_and_cam_heatmap(\n    model,\n    cam_func,\n    superimpose,\n#     cls_true,\n#     class_to_label,\n    cam_name,\n    img,\n):\n\n    # for superimpose\n    img = np.uint8(img)\n\n    # cam / superimpose\n    cls_pred, cam = cam_func(\n        model=model,\n        img_array=np.expand_dims(img, axis=0),\n        last_conv_layer_name=\"top_conv\",\n    )\n    img, heatmap, superimposed_img = superimpose(img, cam)\n\n    fig, axs = plt.subplots(ncols=3, figsize=(9, 4))\n\n    axs[0].imshow(img)\n    axs[0].set_title(\"Original image\")\n    axs[0].axis(\"off\")\n\n    axs[1].imshow(heatmap)\n    axs[1].set_title(\"Heatmap\")\n    axs[1].axis(\"off\")\n\n    axs[2].imshow(superimposed_img)\n    axs[2].set_title(\"Superimposed image\")\n    axs[2].axis(\"off\")\n\n    title = (\n        \"CAM name: \"\n        + cam_name\n#         + \" / True label: \"\n#         + class_to_label[cls_true]\n#         + \" / Predicted label : \"\n#         + class_to_label[cls_pred]\n    )\n    plt.suptitle(title)\n    plt.tight_layout()\n    plt.show()\n# class_dict = {\n#     index: class_name for index, class_name in enumerate(class_names)\n# }\n# print(class_dict)\nimg_path = '/kaggle/input/test-data/test/Oral Cancer/oral_scc_3542.jpg'\nmodel = load_model('/kaggle/input/efficient-net/Efficient Net/Oral Cancer  - EfficientNetB0.keras', compile=False)\nmodel.layers[-1].activation = None\nplot_org_img_and_cam_heatmap(\n    model=model,\n    cam_func=make_gradcam_heatmap,\n    superimpose=superimpose,\n    #cls_true=np.argmax(valid_labels[4]),\n#     class_to_label=class_dict,\n    cam_name=\"Grad-CAM\",\n    img=get_img_array(img_path),\n)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-26T12:54:16.571008Z","iopub.execute_input":"2024-03-26T12:54:16.572385Z","iopub.status.idle":"2024-03-26T12:54:24.176788Z","shell.execute_reply.started":"2024-03-26T12:54:16.572340Z","shell.execute_reply":"2024-03-26T12:54:24.175251Z"},"trusted":true},"execution_count":null,"outputs":[]}]}